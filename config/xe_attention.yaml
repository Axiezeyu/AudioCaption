outputpath: experiments/clotho

feature_file: data/clotho/logmel.hdf5
caption_file: data/clotho/dev.json
vocab_file: data/clotho/vocab.pth
# outputpath: experiments/audiocaps

# feature_file: data/audiocaps/logmel_dev.hdf5
# caption_file_train: data/audiocaps/train.json
# caption_file_val: data/audiocaps/val.json
# vocab_file: data/audiocaps/vocab.pth
zh: False
dataloader_args:
    batch_size: 32
    num_workers: 4
# inputdim: 64
train_percent: 90
# augments: [timemask, freqmask]
augments: []
distributed: False

# scaler: StandardScaler # Can be any of sklearn.preprocessing that supports fit_partial
# scaler_args:
    # with_std : True
    # with_mean : True        

encodermodel: CNN10QEncoder
# encodermodel: CRNNEncoder
encodermodel_args: 
    # Enables the passing of the hidden encoder state to the decoder
    embed_size: 512
pretrained_encoder: experiments/pretrained_encoder/CNN10Q_unbalanced.pth
# load_encoder_params: True
decodermodel: RNNBahdanauAttnDecoder
# decodermodel: RNNLuongAttnDecoder
decodermodel_args:
    embed_size: 512
    rnn_type: GRU
    num_layers: 1
    hidden_size: 512
    # attn_hidden_size: 512 # only for Luong attention
    dropout: 0.5
model: Seq2SeqAttnModel
model_args: {}
# pretrained_word_embedding: data/clotho/embeddings/word2vec_word_512.npy
# tune_word_embedding: True
# load_pretrained: True
# pretrained: experiments/clotho/Seq2SeqAttnModel/2020-12-02_15-44-12_3a09df3a347211eb8877a7e6d58eb40d/run_model_score=0.3590.pt

improvecriterion: score # Can be acc | loss | score

optimizer: Adam
optimizer_args:
    lr: 0.0005
    weight_decay: 0.0
max_grad_norm: 0.5
epochs: 25
early_stop: 5
scheduler: ReduceLROnPlateau
# scheduler: ExponentialLR
scheduler_args:
    mode: min
    factor: 0.1
    patience: 5
    threshold: 0.001
    # gamma: 0.9

ss: False
ss_args:
    ss_mode: linear
    ss_ratio: 1.0
    final_ss_ratio: 0.7

label_smoothing: False
smoothing: 0.1
